 FTP（文件[传输](https://baike.baidu.com/item/传输/7078195)协议的简称）（File Transfer Protocol、 FTP）客户端软件断点续传指的是在下载或上传时，将下载或上传任务（一个文件或一个压缩包）人为的划分为几个部分，每一个部分采用一个[线程](https://baike.baidu.com/item/线程/103101)进行上传或下载，如果碰到[网络故障](https://baike.baidu.com/item/网络故障/1391028)，可以从已经上传或下载的部分开始继续上传下载未完成的部分，而没有必要从头开始上传[下载](https://baike.baidu.com/item/下载/2270927)。用户可以节省时间，提高速度。 



## 用途

有时用户上传下载文件需要历时数小时，万一线路中断，不具备断点续传的[FTP服务器](https://baike.baidu.com/item/FTP服务器)或[下载软件](https://baike.baidu.com/item/下载软件)就只能从头重传，比较好的FTP服务器或下载软件具有FTP断点续传能力，允许用户从上传下载断线的地方继续传送，这样大大减少了用户的烦恼。

[IE浏览器](https://baike.baidu.com/item/IE浏览器)默认下载方式不支持断点续传。

常见的支持断点续传的上传、下载软件：[QQ旋风](https://baike.baidu.com/item/QQ旋风)、[迅雷](https://baike.baidu.com/item/迅雷)、[快车](https://baike.baidu.com/item/快车)（[迷你快车](https://baike.baidu.com/item/迷你快车)）、[web迅雷](https://baike.baidu.com/item/web迅雷)、[影音传送带](https://baike.baidu.com/item/影音传送带)、快车、[BitComet](https://baike.baidu.com/item/BitComet)、[电驴](https://baike.baidu.com/item/电驴)eMule、[哇嘎](https://baike.baidu.com/item/哇嘎)Vagaa、RF[RaySourse/RayFile]、酷6、土豆、优酷、百度视频、新浪视频、腾讯视频、百度云等都支持断点续传。

在 *nix(Linux/Unix)系统下，常用支持断点续传的FTP客户端软件是lftp。



## 特点

断点续传支持从文件上次中断的地方开始传送[数据](https://baike.baidu.com/item/数据/5947370)，而并非是从文件开头传送。

断点续传下载软件具有以下特点：

1、断点续传功能，既可节约时间又可以节约金钱。

2、定时[下载](https://baike.baidu.com/item/下载/2270927)功能，可以为将要下载的软件制定一任务列表，让[下载软件](https://baike.baidu.com/item/下载软件)在规定的时间自动拨号上网并下载软件，下载完毕后再自动挂起[Modem](https://baike.baidu.com/item/Modem/852355)，断开与[internet](https://baike.baidu.com/item/internet/272794)的连接，甚至自动关闭计算机。

3、多文件同时下载。

4、支持拖放式操作，可将下载文件的URL[超链接](https://baike.baidu.com/item/超链接)用鼠标拖放到下载软件的窗口上，即可激活下载软件，同时开始文件的下载。

5、自动捕捉剪贴板上的URL并激活[下载软件](https://baike.baidu.com/item/下载软件)，可以捕捉到剪贴板中的URL，甚至浏览器中单击下载文件超链接，即可激活程序实现文件的下载。

6、致命错误发生时的关闭机制。

7、预防病毒侵害的安全机制，文件下载完毕，即可自动将其发送到指定的病毒的检测软件进行病毒扫描。

断点续传下载软件包括Thunder、NetAnts、FlashGet、Net Vampire、Download Manager、GetRight、Go!Zilla、WinDownload、Internet Download Manager等。



```
import sys
import requests
import os

# 屏蔽warning信息
requests.packages.urllib3.disable_warnings()

def download(url, file_path):
    # 第一次请求是为了得到文件总大小
    r1 = requests.get(url, stream=True, verify=False)
    total_size = int(r1.headers['Content-Length'])

    # 这重要了，先看看本地文件下载了多少
    if os.path.exists(file_path):
        temp_size = os.path.getsize(file_path)  # 本地已经下载的文件大小
    else:
        temp_size = 0
    # 显示一下下载了多少   
    print(temp_size)
    print(total_size)
    # 核心部分，这个是请求下载时，从本地文件已经下载过的后面下载
    headers = {'Range': 'bytes=%d-' % temp_size}  
    # 重新请求网址，加入新的请求头的
    r = requests.get(url, stream=True, verify=False, headers=headers)

    # 下面写入文件也要注意，看到"ab"了吗？
    # "ab"表示追加形式写入文件
    with open(file_path, "ab") as f:
        for chunk in r.iter_content(chunk_size=1024):
            if chunk:
                temp_size += len(chunk)
                f.write(chunk)
                f.flush()

                ###这是下载实现进度显示####
                done = int(50 * temp_size / total_size)
                sys.stdout.write("\r[%s%s] %d%%" % ('█' * done, ' ' * (50 - done), 100 * temp_size / total_size))
                sys.stdout.flush()
    print()  # 避免上面\r 回车符


if __name__ == '__main__':
    link = r'https://api.gdc.cancer.gov/data/'
    UUID = r'2a4a3044-0b1a-4722-83ed-43ba5d6d25b0'
    path = r'F:\SYY\temp\a.txt'
    url = os.path.join(link, UUID)
    # 调用一下函数试试
    download(url, path)

```